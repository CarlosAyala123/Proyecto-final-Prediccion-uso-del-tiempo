c_1 <- rename(c_1, names) ## asignar nuevo nombre a las variables
skim(c_1)
write.csv(c_1, file = "Data/c_4.csv", col.names = T)
c_1 <- read.csv("Data/ENUT_C5/ENUT_C5.csv", header = T)
colnames(c_1) <- tolower(colnames(c_1))
c_1$p1165[c_1$p1165==2]<-0
c_1$p1178s1[is.na(c_1$p1178s1)==T]<-0
c_1$p1178s1[c_1$p1178s1==2]<-0
vars <- c("p1162s1a1", "p1162s2a1", "p1162s3a1", "p1162s4a1", "p1162s5a1", "p1162s6a1", "p1178s1")
for (i in vars){
c_1[,i]<- c_1[,i]*60
}
vars <- c(paste0("p1162s",1:6,"a1"), paste0("p1162s",1:6,"a2"))
c_1 <- mutate_at(c_1, vars, ~replace(., is.na(.), 0))
c_1$tiempo_esparcimiento_ninos <- c_1$p1162s1a1 + c_1$p1162s2a1 + c_1$p1162s3a1 + c_1$p1162s4a1 + c_1$p1162s5a1 + c_1$p1162s6a1 +
c_1$p1162s1a2 + c_1$p1162s2a2 + c_1$p1162s3a2 + c_1$p1162s4a2 + c_1$p1162s5a2 + c_1$p1162s6a2
c_1 <- subset(c_1, select = c(directorio, secuencia_p, orden, p1165, p1178s1,
tiempo_esparcimiento_ninos)) ## dejar las variables a usar
names <- c(directorio = "vivienda", secuencia_p = "hogar", orden = "ind", p1165 = "jardin",
p1178s1 = "tiempo_jardin") ## vercotr de nombres
c_1 <- rename(c_1, names) ## asignar nuevo nombre a las variables
skim(c_1)
write.csv(c_1, file = "Data/c_5.csv", col.names = T)
c_1 <- read.csv("Data/ENUT_C6/ENUT_C6.csv", header = T)
colnames(c_1) <- tolower(colnames(c_1))
c_1$p6160[c_1$p6160==2]<-0
c_1$p1160s1a1<- c_1$p1160s1a1*60
c_1$tiempo_estudio<-c_1$p1160s1a1+c_1$p1160s1a2
c_1$tiempo_estudio[is.na(c_1$tiempo_estudio)==T]<-0
c_1 <- c_1[!is.na(c_1$p6210),] #### quitar na
vars <- c("p1153s1a1", "p1153s2a1", "p1153s3a1", "p1153s4a1", "p1153s5a1", "p1153s6a1")
for (i in vars){
c_1[,i]<- c_1[,i]*60
}
vars <- c(paste0("p1153s",1:6,"a1"), paste0("p1153s",1:6,"a2"))
c_1 <- mutate_at(c_1, vars, ~replace(., is.na(.), 0))
c_1$tiempo_esparcimiento <- c_1$p1153s1a1 + c_1$p1153s2a1 + c_1$p1153s3a1 + c_1$p1153s4a1 + c_1$p1153s5a1 + c_1$p1153s6a1 +
c_1$p1153s1a2 + c_1$p1153s2a2 + c_1$p1153s3a2 + c_1$p1153s4a2 + c_1$p1153s5a2 + c_1$p1153s6a2
c_1 <- subset(c_1, select = c(directorio, secuencia_p, orden, p6160, tiempo_estudio, p6210,
tiempo_esparcimiento)) ## dejar las variables a usar
names <- c(directorio = "vivienda", secuencia_p = "hogar", orden = "ind", p6160 = "leer_escribir",
p6210 = "grado_aprobado") ## vercotr de nombres
c_1 <- rename(c_1, names) ## asignar nuevo nombre a las variables
skim(c_1)
write.csv(c_1, file = "Data/c_6.csv", col.names = T)
c_1 <- read.csv("Data/c_1.csv", header = T)
View(c_1)
for (i in 1:8){
c_i<-read.csv("Data/c_i.csv", header = T)
}
filenames <- list.files("Data", pattern="*.csv", full.names=TRUE)
ldf <- lapply(filenames, read.csv)
Reduce(function(x, y) merge(x, y), list(ldf))
base_final<-Reduce(function(x, y) merge(x, y), list(ldf))
b<-NULL
rm(list=ls())
filenames <- list.files("Data", pattern="*.csv", full.names=TRUE)
ldf <- lapply(filenames, read.csv)
b<-NULL
for (i in ldf){
a <- ldf$`i`
b <- merge(x = b, y = a, all = T)
}
for (i in ldf){
a <- ldf$`i`
b <- merge(x = b, y = a, all = T)
}
for (file in ldf){
a <- ldf$`file`
b <- merge(x = b, y = a, all = T)
}
for (file in ldf){
print(file)
a <- ldf$`file`
b <- merge(x = b, y = a, all = T)
}
a<-NULL
for (file in ldf){
print(file)
a <- ldf$`file`
b <- merge(x = b, y = a, all = T)
}
for (file in ldf){
print(file)
a <- ldf$file
b <- merge(x = b, y = a, all = T)
}
a <- ldf$file
for (i in ldf){
print(i)
a <- ldf$i
b <- merge(x = b, y = a, all = T)
}
rm(list=ls())
filenames <- list.files("Data", pattern="*.csv", full.names=TRUE)
ldf <- lapply(filenames, read.csv)
b<-NULL
a<-NULL
for (i in ldf){
a <- ldf$i
b <- merge(x = b, y = a, all = T)
}
for (i in ldf){
a <- ldf$'i'
b <- merge(x = b, y = a, all = T)
}
a <- ldf$'data.frame'
a <- ldf$`data.frame`
a <- ldf$`c_1.csv`
names(ldf) <- substr(filenames, 6, 30)
for (i in ldf){
a <- ldf$`I`
b <- merge(x = b, y = a, all = T)
}
for (i in ldf){
a <- ldf$`i`
b <- merge(x = b, y = a, all = T)
}
a <- ldf$`c_1csv`
a <- ldf$c_1csv
ldf$c_1.csv
a<-ldf$c_1.csv
for (i in ldf){
a <- ldf$c_1.csv
b <- merge(x = b, y = a, all = T)
}
b<-NULL
a<-NULL
for (i in ldf){
a <- ldf$c_1.csv
b <- merge(x = b, y = a, all = T)
}
b<-NULL
a<-NULL
for (i in ldf){
a <- ldf$i.csv
b <- merge(x = b, y = a, all = T)
}
for (i in ldf){
a <- ldf$i
b <- merge(x = b, y = a, all = T)
}
for (i in 1:8){
a <- ldf$c_i.csv
b <- merge(x = b, y = a, all = T)
}
a<-ldf$c_1.csv
b<-ldf$c_2.csv
c<-ldf$c_3.csv
d<-ldf$c_4.csv
e<-ldf$c_5.csv
f<-ldf$c_6.csv
g<-ldf$c_8.csv
base <- NULL
for (i in 1:7){
a<-c_i
merge(base,a,all=T)
}
for (i in 1:7){
a<-c_`i`
base <- merge(x = a, y = b, all=T)
base <- merge(x = base, y = c, all=T)
a$X<-NULL
b$X<-NULL
c$X<-NULL
d$X<-NULL
e$X<-NULL
f$X<-NULL
g$X<-NULL
mr(list=ls())
rm(list=ls())
filenames <- list.files("Data", pattern="*.csv", full.names=TRUE)
ldf <- lapply(filenames, read.csv)
names(ldf) <- substr(filenames, 6, 30)
a<-ldf$c_1.csv
b<-ldf$c_2.csv
c<-ldf$c_3.csv
d<-ldf$c_4.csv
e<-ldf$c_5.csv
f<-ldf$c_6.csv
g<-ldf$c_8.csv
a$X<-NULL
b$X<-NULL
c$X<-NULL
d$X<-NULL
e$X<-NULL
f$X<-NULL
g$X<-NULL
base <- merge(x = a, y = b, all=T)
base <- merge(x = base, y = c, all=T)
base <- merge(x = a, y = b, all=T)
base <- merge(x = base, y = c, all=T)
base <- Reduce(function(x, y) merge(x, y), list(base, d, e, f, g))
base <- merge(x = a, y = b, all=T)
base <- merge(x = base, y = c, all=T)
base <- merge(x = merge(x = merge(x = merge(x = base, y = d, all=T), y = e, all=T), y = f, all=T), y = g, all=T)
View(base)
#------------------------------------------------------------------------------
# Cargar paquetes
require(pacman)
p_load(tidyverse,dplyr,here,skimr,tidyr,gamlr,modelsummary,caret,
rio,knitr, kableExtra, rstudioapi,tidymodels,janitor,MLmetrics,
reshape,rattle,doParallel,mixgb, install = TRUE)
p_load(mltools, xgboost,
mixgb, vctrs,
mlr, spdep,
install = T)
skim(base)
write.csv(base, file = "Data1/base_final.csv")
write.csv(base, file = "Data/base_final.csv")
base <- read.csv(file = "Data/base_final.csv", header = T)
base$X<-NULL
skim(base)
base <- na.omit(base)
skim(base)
base <- read.csv(file = "Data/base_final.csv", header = T)
base$X<-NULL
skim(base)
base <- base[!is.na(base$ind),] #### quitar na
skim(base)
base <- base[!is.na(base$tipo_vivienda),]
skim(base)
rm(list=ls())
filenames <- list.files("Data", pattern="*.csv", full.names=TRUE)
ldf <- lapply(filenames, read.csv)
names(ldf) <- substr(filenames, 6, 30)
a<-ldf$c_1.csv
b<-ldf$c_2.csv
c<-ldf$c_3.csv
d<-ldf$c_4.csv
e<-ldf$c_5.csv
f<-ldf$c_6.csv
g<-ldf$c_8.csv
a$X<-NULL
b$X<-NULL
c$X<-NULL
d$X<-NULL
e$X<-NULL
f$X<-NULL
g$X<-NULL
base <- merge(x = a, y = b, all=T)
base <- merge(x = base, y = c, all=T)
base <- merge(x = merge(x = merge(x = base, y = d, all=T), y = f, all=T), y = g, all=T)
write.csv(base, file = "Data/base_final.csv")
base <- read.csv(file = "Data/base_final.csv", header = T)
base$X<-NULL
base <- base[!is.na(base$ind),] #### quitar na
base <- base[!is.na(base$tipo_vivienda),]
skim(base)
base <- read.csv(file = "Data/base_final.csv", header = T)
base$X<-NULL
base <- base[!is.na(base$ind),] #### quitar na
base <- base[!is.na(base$tipo_vivienda),]
skim(base)
base <- base[!is.na(base$leer_escribir),]
skim(base)
write.csv(base, file = "Data/base_final_na.csv")
base <- read.csv(file = "Data/base_final_na.csv", header = T)
base$X<-NULL
table(base$mujer)
base <- read.csv(file = "Data/base_final.csv", header = T)
base$X<-NULL
skim(base)
base <- read.csv(file = "Data/base_final_na.csv", header = T)
base$X<-NULL
table(base$mujer)
mujer <- subset(base, mujer == 1)
hombre <- subset(base, mujer == 0)
mujer <- subset(base, mujer == 1)
hombre <- subset(base, mujer == 0)
mujer$mujer<-NULL
hombre$mujer<-NULL
## 75% of the sample size
smp_size <- floor(0.75 * nrow(mujer))
## set the seed to make your partition reproducible
set.seed(10101)
train_ind <- sample(seq_len(nrow(mujer)), size = smp_size)
m_train <- df[train_ind, ]
m_test <- df[-train_ind, ]
m_train <- df[train_ind, ]
inTrain<- createDataPartition(y=mujer,p=0.75,list=FALSE)
train_ind <- sample(seq_len(nrow(mujer)), size = smp_size)
m_train <- df[train_ind, ]
m_test <- df[-train_ind, ]
m_train <- mujer[train_ind, ]
m_test <- mujer[-train_ind, ]
## 75% of the sample size
smp_size <- floor(0.75 * nrow(hombre))
## set the seed to make your partition reproducible
set.seed(10101)
train_ind <- sample(seq_len(nrow(hombre)), size = smp_size)
h_train <- hombre[train_ind, ]
h_test <- hombre[-train_ind, ]
rm(a,b,c,d,e,f,g,ldf,filenames,smp_size,train_ind)
rm(base, hombre, mujer)
#------------------------------------------------------------------------------
# Cargar paquetes
require(pacman)
p_load(tidyverse,dplyr,here,skimr,tidyr,gamlr,modelsummary,caret,
rio,knitr, kableExtra, rstudioapi,tidymodels,janitor,MLmetrics,
reshape,rattle,doParallel,mixgb, install = TRUE)
p_load(mltools, xgboost,
mixgb, vctrs,
mlr, spdep,
install = T)
## set n-folds
set.seed(234)
db_folds <- vfold_cv(data=m_train, v=10 , strata=NULL)
db_folds
## set metrics
db_metrics <- metric_set(yardstick::rmse, yardstick::rsq, ccc) ## para categoricas, la última es la función de perdida. RMSE para regresion
## Boosted Tree Model Specification
xgb_spec <- boost_tree(trees = 1000,
tree_depth = tune(),
min_n = tune(),
mtry = tune(),
sample_size = tune(),
learn_rate = tune()) %>%
set_engine("xgboost") %>%
set_mode("regression") ## para regresión cambiar classification por regress
xgb_spec
## workflow
xgb_word_wf <- workflow(train_recipe, xgb_spec)
## tunne hiperparametros
xgb_grid <- grid_max_entropy(tree_depth(c(5L, 10L)),
min_n(c(10L, 40L)),
mtry(c(5L, 10L)),
sample_prop(c(0.5, 1.0)),
learn_rate(c(-2, -1)),
size = 20)
## tunne hiperparametros
xgb_grid <- grid_max_entropy(tree_depth(c(5L, 10L)),
min_n(c(10L, 40L)),
mtry(c(5L, 10L)),
sample_prop(c(0.5, 1.0)),
learn_rate(c(-2, -1)),
size = 20)
xgb_grid
tic()
p_load(tidyverse,dplyr,here,skimr,tidyr,gamlr,modelsummary,caret,
rio,knitr, kableExtra, rstudioapi,tidymodels,janitor,MLmetrics,
reshape,rattle,doParallel,mixgb, tic, install = TRUE)
p_load(tidyverse,dplyr,here,skimr,tidyr,gamlr,modelsummary,caret,
rio,knitr, kableExtra, rstudioapi,tidymodels,janitor,MLmetrics,
reshape,rattle,doParallel,mixgb, tictoc, install = TRUE)
p_load(mltools, xgboost,
mixgb, vctrs,
mlr, spdep,
install = T)
## workflow
xgb_word_wf <- workflow(train_recipe, xgb_spec)
## workflow
xgb_word_wf <- workflow(m_train, xgb_spec)
m_train_recipe <- recipe(formula=price ~ . , data=m_train) %>% ## En recip se detallan los pasos que se aplicarán a un conjunto de datos para prepararlo para el análisis de datos.
)
m_train_recipe <- recipe(formula=price ~ . , data=m_train) %>% ## En recip se detallan los pasos que se aplicarán a un conjunto de datos para prepararlo para el análisis de datos.
update_role(c("vivienda", "hogar", "ind"), new_role = "property_id")
rm(list=ls())
filenames <- list.files("Data", pattern="*.csv", full.names=TRUE)
ldf <- lapply(filenames, read.csv)
names(ldf) <- substr(filenames, 6, 30)
a<-ldf$c_1.csv
b<-ldf$c_2.csv
c<-ldf$c_3.csv
d<-ldf$c_4.csv
e<-ldf$c_5.csv
f<-ldf$c_6.csv
g<-ldf$c_8.csv
a$X<-NULL
b$X<-NULL
c$X<-NULL
d$X<-NULL
e$X<-NULL
f$X<-NULL
g$X<-NULL
base <- merge(x = a, y = b, all=T)
base <- merge(x = base, y = c, all=T)
base <- merge(x = merge(x = merge(x = base, y = d, all=T), y = f, all=T), y = g, all=T)
colnames(base) <- tolower(colnames(base))
write.csv(base, file = "Data/base_final.csv")
base <- read.csv(file = "Data/base_final.csv", header = T)
base$X<-NULL
base <- base[!is.na(base$ind),] #### quitar na
base <- base[!is.na(base$tipo_vivienda),]
base <- base[!is.na(base$leer_escribir),]
#base <- na.omit(base)
skim(base)
write.csv(base, file = "Data/base_final_na.csv")
base <- read.csv(file = "Data/base_final_na.csv", header = T)
base$X<-NULL
table(base$mujer)
# Mujer
mujer <- subset(base, mujer == 1)
mujer$mujer<-NULL
## 75% of the sample size
smp_size <- floor(0.75 * nrow(mujer))
## set the seed to make your partition reproducible
set.seed(10101)
train_ind <- sample(seq_len(nrow(mujer)), size = smp_size)
m_train <- mujer[train_ind, ]
m_test <- mujer[-train_ind, ]
# Hombre
hombre <- subset(base, mujer == 0)
hombre$mujer<-NULL
## 75% of the sample size
smp_size <- floor(0.75 * nrow(hombre))
## set the seed to make your partition reproducible
set.seed(10101)
train_ind <- sample(seq_len(nrow(hombre)), size = smp_size)
h_train <- hombre[train_ind, ]
h_test <- hombre[-train_ind, ]
rm(a,b,c,d,e,f,g,ldf,hombre,mujer,filenames,smp_size,train_ind)
rm(base)
m_train_recipe <- recipe(formula= Tiempo_labores_no_rem~ . , data=m_train) %>% ## En recip se detallan los pasos que se aplicarán a un conjunto de datos para prepararlo para el análisis de datos.
update_role(c("vivienda", "hogar", "ind"), new_role = "property_id")
m_train_recipe <- recipe(formula= tiempo_labores_no_rem~ . , data=m_train) %>% ## En recip se detallan los pasos que se aplicarán a un conjunto de datos para prepararlo para el análisis de datos.
update_role(c("vivienda", "hogar", "ind"), new_role = "property_id")
test_recipe
m_train_recipe
m_train_recipe <- recipe(formula= tiempo_labores_no_rem~ . , data=m_train) %>% ## En recip se detallan los pasos que se aplicarán a un conjunto de datos para prepararlo para el análisis de datos.
update_role(c("vivienda", "hogar", "ind"), new_role = "id")
m_train_recipe
## set n-folds
set.seed(234)
db_folds <- vfold_cv(data=m_train, v=10 , strata=NULL)
db_folds
## set metrics
db_metrics <- metric_set(yardstick::rmse, yardstick::rsq, ccc) ## para categoricas, la última es la función de perdida. RMSE para regresion
## Boosted Tree Model Specification
xgb_spec <- boost_tree(trees = 1000,
tree_depth = tune(),
min_n = tune(),
mtry = tune(),
sample_size = tune(),
learn_rate = tune()) %>%
set_engine("xgboost") %>%
set_mode("regression") ## para regresión cambiar classification por regress
xgb_spec
## workflow
xgb_word_wf <- workflow(m_train_recipe, xgb_spec)
## tunne hiperparametros
xgb_grid <- grid_max_entropy(tree_depth(c(5L, 10L)),
min_n(c(10L, 40L)),
mtry(c(5L, 10L)),
sample_prop(c(0.5, 1.0)),
learn_rate(c(-2, -1)),
size = 20)
xgb_grid
tic()
xgb_word_rs <- tune_race_anova(object = xgb_word_wf,
resamples = db_folds,
grid = xgb_grid,
metrics = db_metrics,
control = control_race(verbose_elim = T))
p_load(tidyverse,dplyr,here,skimr,tidyr,gamlr,modelsummary,caret,
rio,knitr, kableExtra, rstudioapi,tidymodels,janitor,MLmetrics,
reshape,rattle,doParallel,mixgb, tictoc, install = TRUE)
p_load(mltools, xgboost,
mixgb, vctrs,
mlr, spdep,
install = T)
p_load(tidyverse,
rio,
sf,
leaflet,
tmaptools,
ggsn,
osmdata,
dplyr,
skimr,
tidyr,
janitor,
mixgb, #XGBoost
rstudioapi,
tictoc, ##Saber cuanto demora corriendo el script
rlang)
## estimate model
tic()
xgb_word_rs <- tune_race_anova(object = xgb_word_wf,
resamples = db_folds,
grid = xgb_grid,
metrics = db_metrics,
control = control_race(verbose_elim = T))
p_load(tidyverse,rio,glue,
hexbin,
patchwork,vip, ## plot:
ggrepel, ## plot: geom_text_repel
stringi,tidytext,stopwords, ## text-data
tidymodels,finetune)
tic()
xgb_word_rs <- tune_trace_anova(object = xgb_word_wf,
resamples = db_folds,
grid = xgb_grid,
metrics = db_metrics,
control = control_race(verbose_elim = T))
#------------------------------------------------------------------------------
# Cargar paquetes
require(pacman)
p_load(tidyverse,dplyr,here,skimr,tidyr,gamlr,modelsummary,caret,
rio,knitr, kableExtra, rstudioapi,tidymodels,janitor,MLmetrics,
reshape,rattle,doParallel,mixgb, tictoc, install = TRUE)
p_load(mltools, xgboost,
mixgb, vctrs,
mlr, spdep,
install = T)
p_load(tidyverse,rio,glue,
hexbin,
patchwork,vip, ## plot:
ggrepel, ## plot: geom_text_repel
stringi,tidytext,stopwords, ## text-data
tidymodels,finetune)
set.seed(666)
